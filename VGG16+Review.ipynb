{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4_202150756.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "69953df16d9b4106abfc1ce9bfe953a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_db65522191f64b4fb98f51924b8d5cbe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c4bd68c2acac4803a737fa673e4585b7",
              "IPY_MODEL_5224db83e9ca40fdb30a71aa87eff7c4",
              "IPY_MODEL_dade02c3735743d89b488597b6102b34"
            ]
          }
        },
        "db65522191f64b4fb98f51924b8d5cbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4bd68c2acac4803a737fa673e4585b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e68212e31fe045a0886f9d3f1f0d54e5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f749cd4bac584451a37745532c720af6"
          }
        },
        "5224db83e9ca40fdb30a71aa87eff7c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b39b0b3c3d334a9092ed73d455f4f1d5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_15262ead73ac445e9c3bb3616ab07ed9"
          }
        },
        "dade02c3735743d89b488597b6102b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a2b8f0729b2245eb8b86454c96f68ce8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:05&lt;00:00, 95.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_919374ecddea40ac91f6fec7ca7a5c39"
          }
        },
        "e68212e31fe045a0886f9d3f1f0d54e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f749cd4bac584451a37745532c720af6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b39b0b3c3d334a9092ed73d455f4f1d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "15262ead73ac445e9c3bb3616ab07ed9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2b8f0729b2245eb8b86454c96f68ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "919374ecddea40ac91f6fec7ca7a5c39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CatalystM47/Deep_Learning/blob/main/VGG16%2BReview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOWC1Udun8y0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89bf2115-38db-45d0-939a-62216d0ce425"
      },
      "source": [
        "!apt install unzip\n",
        "!unzip hw4_doghole_keeper.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Archive:  hw4_doghole_keeper.zip\n",
            "  inflating: train/bo/bo_1.jpg       \n",
            "  inflating: train/bo/bo_10.jpg      \n",
            "  inflating: train/bo/bo_11.jpg      \n",
            "  inflating: train/bo/bo_12.jpg      \n",
            " extracting: train/bo/bo_13.jpg      \n",
            "  inflating: train/bo/bo_14.jpg      \n",
            "  inflating: train/bo/bo_15.jpg      \n",
            "  inflating: train/bo/bo_16.jpg      \n",
            "  inflating: train/bo/bo_17.jpg      \n",
            "  inflating: train/bo/bo_18.jpg      \n",
            "  inflating: train/bo/bo_19.jpg      \n",
            "  inflating: train/bo/bo_2.jpg       \n",
            "  inflating: train/bo/bo_3.jpg       \n",
            "  inflating: train/bo/bo_4.jpg       \n",
            "  inflating: train/bo/bo_5.jpg       \n",
            "  inflating: train/bo/bo_6.jpg       \n",
            "  inflating: train/bo/bo_7.jpg       \n",
            "  inflating: train/bo/bo_8.jpg       \n",
            "  inflating: train/bo/bo_9.jpg       \n",
            "  inflating: train/not_bo/1.jpg      \n",
            "  inflating: train/not_bo/10.jpg     \n",
            "  inflating: train/not_bo/100.jpg    \n",
            "  inflating: train/not_bo/101.jpg    \n",
            "  inflating: train/not_bo/102.jpg    \n",
            "  inflating: train/not_bo/103.jpg    \n",
            "  inflating: train/not_bo/104.jpg    \n",
            "  inflating: train/not_bo/105.jpg    \n",
            "  inflating: train/not_bo/106.jpg    \n",
            "  inflating: train/not_bo/107.jpg    \n",
            "  inflating: train/not_bo/108.jpg    \n",
            "  inflating: train/not_bo/109.jpg    \n",
            "  inflating: train/not_bo/11.jpg     \n",
            "  inflating: train/not_bo/110.jpg    \n",
            "  inflating: train/not_bo/111.jpg    \n",
            "  inflating: train/not_bo/112.jpg    \n",
            "  inflating: train/not_bo/113.jpg    \n",
            "  inflating: train/not_bo/114.jpg    \n",
            "  inflating: train/not_bo/115.jpg    \n",
            "  inflating: train/not_bo/116.jpg    \n",
            "  inflating: train/not_bo/117.jpg    \n",
            "  inflating: train/not_bo/118.jpg    \n",
            "  inflating: train/not_bo/119.jpg    \n",
            "  inflating: train/not_bo/12.jpg     \n",
            "  inflating: train/not_bo/120.jpg    \n",
            "  inflating: train/not_bo/13.jpg     \n",
            "  inflating: train/not_bo/14.jpg     \n",
            "  inflating: train/not_bo/15.jpg     \n",
            "  inflating: train/not_bo/16.jpg     \n",
            "  inflating: train/not_bo/17.jpg     \n",
            "  inflating: train/not_bo/18.jpg     \n",
            "  inflating: train/not_bo/19.jpg     \n",
            "  inflating: train/not_bo/2.jpg      \n",
            "  inflating: train/not_bo/20.jpg     \n",
            "  inflating: train/not_bo/21.jpg     \n",
            "  inflating: train/not_bo/22.jpg     \n",
            "  inflating: train/not_bo/23.jpg     \n",
            "  inflating: train/not_bo/24.jpg     \n",
            "  inflating: train/not_bo/25.jpg     \n",
            "  inflating: train/not_bo/26.jpg     \n",
            "  inflating: train/not_bo/27.jpg     \n",
            "  inflating: train/not_bo/28.jpg     \n",
            "  inflating: train/not_bo/29.jpg     \n",
            "  inflating: train/not_bo/3.jpg      \n",
            "  inflating: train/not_bo/30.jpg     \n",
            "  inflating: train/not_bo/31.jpg     \n",
            "  inflating: train/not_bo/32.jpg     \n",
            "  inflating: train/not_bo/33.jpg     \n",
            "  inflating: train/not_bo/34.jpg     \n",
            "  inflating: train/not_bo/35.jpg     \n",
            "  inflating: train/not_bo/36.jpg     \n",
            "  inflating: train/not_bo/37.jpg     \n",
            "  inflating: train/not_bo/38.jpg     \n",
            "  inflating: train/not_bo/39.jpg     \n",
            "  inflating: train/not_bo/4.jpg      \n",
            "  inflating: train/not_bo/40.jpg     \n",
            "  inflating: train/not_bo/41.jpg     \n",
            "  inflating: train/not_bo/42.jpg     \n",
            "  inflating: train/not_bo/43.jpg     \n",
            "  inflating: train/not_bo/44.jpg     \n",
            "  inflating: train/not_bo/45.jpg     \n",
            "  inflating: train/not_bo/46.jpg     \n",
            "  inflating: train/not_bo/47.jpg     \n",
            "  inflating: train/not_bo/48.jpg     \n",
            "  inflating: train/not_bo/49.jpg     \n",
            "  inflating: train/not_bo/5.jpg      \n",
            "  inflating: train/not_bo/50.jpg     \n",
            "  inflating: train/not_bo/51.jpg     \n",
            "  inflating: train/not_bo/52.jpg     \n",
            "  inflating: train/not_bo/53.jpg     \n",
            "  inflating: train/not_bo/54.jpg     \n",
            "  inflating: train/not_bo/55.jpg     \n",
            "  inflating: train/not_bo/56.jpg     \n",
            "  inflating: train/not_bo/57.jpg     \n",
            "  inflating: train/not_bo/58.jpg     \n",
            "  inflating: train/not_bo/59.jpg     \n",
            "  inflating: train/not_bo/6.jpg      \n",
            "  inflating: train/not_bo/60.jpg     \n",
            "  inflating: train/not_bo/61.jpg     \n",
            "  inflating: train/not_bo/62.jpg     \n",
            "  inflating: train/not_bo/63.jpg     \n",
            "  inflating: train/not_bo/64.jpg     \n",
            "  inflating: train/not_bo/65.jpg     \n",
            "  inflating: train/not_bo/66.jpg     \n",
            "  inflating: train/not_bo/67.jpg     \n",
            "  inflating: train/not_bo/68.jpg     \n",
            "  inflating: train/not_bo/69.jpg     \n",
            "  inflating: train/not_bo/7.jpg      \n",
            "  inflating: train/not_bo/70.jpg     \n",
            "  inflating: train/not_bo/71.jpg     \n",
            "  inflating: train/not_bo/72.jpg     \n",
            "  inflating: train/not_bo/73.jpg     \n",
            "  inflating: train/not_bo/74.jpg     \n",
            "  inflating: train/not_bo/75.jpg     \n",
            "  inflating: train/not_bo/76.jpg     \n",
            "  inflating: train/not_bo/77.jpg     \n",
            "  inflating: train/not_bo/78.jpg     \n",
            "  inflating: train/not_bo/79.jpg     \n",
            "  inflating: train/not_bo/8.jpg      \n",
            "  inflating: train/not_bo/80.jpg     \n",
            "  inflating: train/not_bo/81.jpg     \n",
            "  inflating: train/not_bo/82.jpg     \n",
            "  inflating: train/not_bo/83.jpg     \n",
            "  inflating: train/not_bo/84.jpg     \n",
            "  inflating: train/not_bo/85.jpg     \n",
            "  inflating: train/not_bo/86.jpg     \n",
            "  inflating: train/not_bo/87.jpg     \n",
            "  inflating: train/not_bo/88.jpg     \n",
            "  inflating: train/not_bo/89.jpg     \n",
            "  inflating: train/not_bo/9.jpg      \n",
            "  inflating: train/not_bo/90.jpg     \n",
            "  inflating: train/not_bo/91.jpg     \n",
            "  inflating: train/not_bo/92.jpg     \n",
            "  inflating: train/not_bo/93.jpg     \n",
            "  inflating: train/not_bo/94.jpg     \n",
            "  inflating: train/not_bo/95.jpg     \n",
            "  inflating: train/not_bo/96.jpg     \n",
            "  inflating: train/not_bo/97.jpg     \n",
            "  inflating: train/not_bo/98.jpg     \n",
            "  inflating: train/not_bo/99.jpg     \n",
            "  inflating: valid/bo/bo_20.jpg      \n",
            "  inflating: valid/bo/bo_21.jpg      \n",
            "  inflating: valid/bo/bo_22.jpg      \n",
            " extracting: valid/bo/bo_23.jpg      \n",
            "  inflating: valid/bo/bo_24.jpg      \n",
            "  inflating: valid/bo/bo_25.jpg      \n",
            "  inflating: valid/bo/bo_26.jpg      \n",
            "  inflating: valid/bo/bo_27.jpg      \n",
            "  inflating: valid/bo/bo_28.jpg      \n",
            "  inflating: valid/bo/bo_29.jpg      \n",
            "  inflating: valid/not_bo/121.jpg    \n",
            "  inflating: valid/not_bo/122.jpg    \n",
            "  inflating: valid/not_bo/123.jpg    \n",
            "  inflating: valid/not_bo/124.jpg    \n",
            "  inflating: valid/not_bo/125.jpg    \n",
            "  inflating: valid/not_bo/126.jpg    \n",
            "  inflating: valid/not_bo/127.jpg    \n",
            "  inflating: valid/not_bo/128.jpg    \n",
            "  inflating: valid/not_bo/129.jpg    \n",
            "  inflating: valid/not_bo/130.jpg    \n",
            "  inflating: valid/not_bo/131.jpg    \n",
            "  inflating: valid/not_bo/132.jpg    \n",
            "  inflating: valid/not_bo/133.jpg    \n",
            "  inflating: valid/not_bo/134.jpg    \n",
            "  inflating: valid/not_bo/135.jpg    \n",
            "  inflating: valid/not_bo/136.jpg    \n",
            "  inflating: valid/not_bo/137.jpg    \n",
            "  inflating: valid/not_bo/138.jpg    \n",
            "  inflating: valid/not_bo/139.jpg    \n",
            "  inflating: valid/not_bo/140.jpg    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzs7MesSpNfY"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torchvision import transforms as T\n",
        "import torchvision.models as models\n",
        "\n",
        "import sys\n",
        "sys.setrecursionlimit(10000)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HIDEkm_wp49i"
      },
      "source": [
        "### 1. Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40VDwtJ6p6Jb"
      },
      "source": [
        "transform = T.Compose([T.Resize(256), T.RandomCrop(224), T.ToTensor()])\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, path='train'):\n",
        "        super(Dataset, self).__init__()\n",
        "\n",
        "        self.img_path = []\n",
        "        bo_path = glob.glob(path + '/bo/*.jpg')\n",
        "        notbo_path = glob.glob(path + '/not_bo/*.jpg')\n",
        "        self.img_path = bo_path + notbo_path\n",
        "\n",
        "        self.label_list = [1]*len(bo_path) + [0]*len(notbo_path)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = cv2.imread(self.img_path[index])\n",
        "        \n",
        "        img_pil = Image.fromarray(img)\n",
        "        self.img_tensor = transform(img_pil)\n",
        "\n",
        "        self.label_tensor = torch.tensor(self.label_list[index])\n",
        "\n",
        "        return self.img_tensor.to('cuda:0'), self.label_tensor.to('cuda:0')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe3oaXeYsGS4"
      },
      "source": [
        "training_dataset = Dataset('train')\n",
        "training_loader = DataLoader(dataset=training_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "validation_dataset = Dataset('valid')\n",
        "validation_loader = DataLoader(dataset=validation_dataset, batch_size=8, shuffle=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp_HOtGnswEP"
      },
      "source": [
        "### 2. Constructing a convolutional neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "69953df16d9b4106abfc1ce9bfe953a1",
            "db65522191f64b4fb98f51924b8d5cbe",
            "c4bd68c2acac4803a737fa673e4585b7",
            "5224db83e9ca40fdb30a71aa87eff7c4",
            "dade02c3735743d89b488597b6102b34",
            "e68212e31fe045a0886f9d3f1f0d54e5",
            "f749cd4bac584451a37745532c720af6",
            "b39b0b3c3d334a9092ed73d455f4f1d5",
            "15262ead73ac445e9c3bb3616ab07ed9",
            "a2b8f0729b2245eb8b86454c96f68ce8",
            "919374ecddea40ac91f6fec7ca7a5c39"
          ]
        },
        "id": "9WxHiPWus1zT",
        "outputId": "11e51045-5ac7-401f-dbcc-f1c85a30eaee"
      },
      "source": [
        "#vgg16 = models.vgg16()\n",
        "vgg16 = models.vgg16(pretrained=True)\n",
        "for param in vgg16.parameters():\n",
        "   param.requires_grad = False"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69953df16d9b4106abfc1ce9bfe953a1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJ6Wo0HItBEZ"
      },
      "source": [
        "num_features = vgg16.classifier[0].in_features\n",
        "vgg16.classifier = nn.Sequential(\n",
        "    nn.Linear(num_features, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(256, 2)\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOjVfbTAtb69"
      },
      "source": [
        "vgg16 = vgg16.to('cuda:0')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55eh5UoRuN4o"
      },
      "source": [
        "### 3. Loss function and optimization method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jESJej1OuIDA"
      },
      "source": [
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(vgg16.parameters(), lr=0.0001)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6v_topo3Qk7"
      },
      "source": [
        "### 4. Training of a neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDWlviyK3CfA",
        "outputId": "32037840-e876-4f95-fcac-195b8954bfb4"
      },
      "source": [
        "for epoch in range(10):\n",
        "    loss_val = 0\n",
        "\n",
        "    for itr, data in enumerate(training_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs, labels = data\n",
        "\n",
        "        pred = vgg16(inputs)\n",
        "        loss = loss_function(pred, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_val += loss.item()\n",
        "\n",
        "    print(\"Epoch:\", epoch+1, \"  , Loss:\", loss_val)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1   , Loss: 5.371090192347765\n",
            "Epoch: 2   , Loss: 0.4729023745749146\n",
            "Epoch: 3   , Loss: 0.4402293391249259\n",
            "Epoch: 4   , Loss: 0.07950235097814584\n",
            "Epoch: 5   , Loss: 0.0281783010577783\n",
            "Epoch: 6   , Loss: 0.03124845018464839\n",
            "Epoch: 7   , Loss: 0.051500726832728105\n",
            "Epoch: 8   , Loss: 0.014362634672579588\n",
            "Epoch: 9   , Loss: 0.01446219440549612\n",
            "Epoch: 10   , Loss: 0.016702202377359754\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R23iAi1O5Ba5"
      },
      "source": [
        "### 5. Prediction and evaluationfor the validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUkGqu9B37S2",
        "outputId": "1f525a22-7e65-4f11-8618-15030ac38bac"
      },
      "source": [
        "pred_list = []\n",
        "label_list = []\n",
        "\n",
        "for itr, data in enumerate(validation_loader):\n",
        "    inputs, labels = data\n",
        "\n",
        "    pred = vgg16(inputs)\n",
        "    pred_category = torch.argmax(pred, dim=1)\n",
        "\n",
        "    pred_list = pred_list + list(pred_category)\n",
        "    label_list = label_list + list(labels)\n",
        "\n",
        "accu = np.mean( np.array(pred_list) == np.array(label_list) )\n",
        "print(\"Val accu:\", accu)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val accu: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUhwoYAavkg3"
      },
      "source": [
        "@@ 딥러닝을 해야하는데 데이터셋이 너무 적을때 처리하는 방법 @@\n",
        "\n",
        "1. !apt install unzip으로 압축풀기 프로그램 인스톨\n",
        "2. Dataset Zip 파일 압축 풀기\n",
        "\n",
        "1. 배열 사용 위해 numpy 이용\n",
        "2. 이미지 처리 위해 cv2 이용\n",
        "3. 원하는 파일 경로 찾기위해 glob이용\n",
        "4. PIL == Python Image Library 파이썬으로 이미지 파일 사용 위해 이용\n",
        "\n",
        "###(1)###\n",
        "1. Dataset 클래스에서 다른 클래스로 init 상속위해 super이용\n",
        "2. 이미지 경로 저장 위한 리스트 생성\n",
        "3. bo_path에 bo 디렉터리 안의 모든 .jpg파일 경로 저장 (*은 모든 것을 뜻하는 asterisk)\n",
        "4. not_bo도 동일\n",
        "5. img path라는 모든 이미지의 경로를 포함한 리스트를 생성\n",
        "6. bo인 이미지의 경로는 인덱스 [0]으로 라벨링, not_bo인 이미지의 경로는 인덱스[1]으로 라벨링\n",
        "7. 아이템을 외부에서 가져오기 위해 getitem 생성.\n",
        "이미지를 openCV 라이브러리를 이용하여 읽음, transform을 거친 것을 img_tensor로 저장\n",
        "label_list들을 label_tensor로 저장 후 img_tensor와 label_tensor로 반환하는데, GPU메모리를 사용하기 위해\n",
        "tensor.to('cuda:0')적용 (GPU Cuda 검색해보면 이해 가능)\n",
        "8. 길이 return 위한 len 생성\n",
        "이미지 path의 길이를 반환\n",
        "9. transform을 사용하기위해 T.Compose 함수 사용 -> 이미지를 256size로 변경하고, 224size로 랜덤하게 잘라내며, 텐서 형태로 변경함\n",
        "\n",
        "1. train에서 가져온 데이터를 데이터셋으로 만들어서 training_dataset으로 입력\n",
        "2. 트레이닝을 위해 데이터 로더 생성, 데이터셋은 training_dataset을 사용하며, 배치 사이즈는 8개씩, 데이터를 무작위로 섞어 트레이닝\n",
        "3. 검증위한 데이터 valid에서 가져온 데이터일 뿐, 나머지는 1과 같음\n",
        "4. 검증을 위한 것이므로 섞을 필요는 없음\n",
        "\n",
        "###(2)###\n",
        "1. vgg16모델을 이용할 예정\n",
        "2. vgg16모델의 형태를 확인\n",
        "3. features의 숫자를 확인하기 위함\n",
        "4. vgg16 classifier 정의. input feature를 256으로 줄이고 ReLU 실행, 최종 fully connected Layer의 결과가 2가 나오도록 설정.\n",
        "5. vgg16을 cuda로 실행\n",
        "\n",
        "###(3)###\n",
        "1. Loss Function으로 Cross EntropyLoss사용\n",
        "2. Optimizer는 Adam 사용 (Cross Entropy와 Adam은 찾아볼것), Learning_rate는 0.001 (LearningRate도 찾아보세요)\n",
        "\n",
        "###(4)###\n",
        "1. epoch(batch size만큼 나눠서 총 몇번 트레이닝 하는가)는 20으로 설정. LossVal = 0 으로 쓰레기 값 안들어가있게 초기화\n",
        "2. 매 iteration에서는 training_loader를 자동으로 연산.\n",
        "3. pred, loss, backward는 찾아보시는게 좋습니다. 특히 backward func는 역전파 함수로 알려져 있는데 중요해요.\n",
        "4. (데이터가 PIL형식이 아니라, Numpy array라서 에러뜸) -> 기존에 numpy array형식으로 데이터가 들어간걸 컴퓨터가 기억하므로, 런타임을 초기화해서 기억 지우고 새로 시작하기 (새로 시작하면 PIL형식으로 데이터가 들어온걸로 인지함)\n",
        "5. 첫번째 Epoch에서는 드라마틱하게 Loss가 줄어드나, 그 후로는 어느 이상 줄지 않음\n",
        "6. Epoch 20 후 트레이닝 완료됨. 이제 검증데이터로 확인해야함\n",
        "\n",
        "###(5)###\n",
        "1. 검증을 하기위해 내가 모델을 통해 예측한 값을 넣을 pred_list 생성, 실제 값인 label_list 생성\n",
        "2. validation loader를 연산한 값을 inputs, labels에 넣기\n",
        "3. input (검증 데이터셋)을 vgg16으로 연산하여 예측한 값을 pred에 넣기\n",
        "4. torch.argmax는 찾아보세요\n",
        "5. 예측값 리스트 생성\n",
        "6. 실제값 리스트 생성\n",
        "7. accuray = 예측값 리스트와 실제값 리스트가 얼마나 같은지 수치값으로 정의\n",
        "8. 정확도 출력.\n",
        "\n",
        "###\n",
        "처음으로 돌아가서 2번에 vgg16모델을 미리 트레이닝 시켜놓는 방법(pretraining) 이용한다는 것, 다시 pretraining한 후 \n",
        "epoch를 10으로 줄여서 트레이닝 했음에도 불구하고, accuracy 확인하니 66%에서 90%로 훨씬 높아짐.\n"
      ]
    }
  ]
}